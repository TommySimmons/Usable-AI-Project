{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2785c40e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f74a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa07e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID        Theme Sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "74681      9200       Nvidia  Positive   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74682 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID      int64\n",
      "Theme        object\n",
      "Sentiment    object\n",
      "Tweet        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#importing the CSV files into Jupyter using Pandas\n",
    "import pandas as pd\n",
    "\n",
    "training_data = pd.read_csv('twitter_training.csv')\n",
    "display(training_data)\n",
    "print(training_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544cac6b",
   "metadata": {},
   "source": [
    "# Checking for null values and removing them if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf07662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(training_data.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a112c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03f9f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  im getting on borderlands and i will murder yo...  Positive\n",
       "1  I am coming to the borders and I will kill you...  Positive\n",
       "2  im getting on borderlands and i will kill you ...  Positive\n",
       "3  im coming on borderlands and i will murder you...  Positive\n",
       "4  im getting on borderlands 2 and i will murder ...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = training_data[['Tweet', 'Sentiment']]\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9897ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e471727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing and initalizing all pre-proccessing tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "\n",
    "\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ade36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'did', 'isn', \"shan't\", 'having', 'am', 'most', 'on', 'any', 'haven', 'has', 'these', 'yourselves', 'have', \"haven't\", 'the', 'can', 'my', \"you're\", \"weren't\", 'over', 'your', 'hers', 'during', 'that', \"aren't\", 'out', 'their', 'no', 'because', 'nor', 'than', 'herself', 'being', 'mightn', 'an', \"you'd\", 'you', 'ourselves', 'should', 'couldn', 'wasn', 'where', 'i', 'whom', \"couldn't\", 'here', 'now', 'myself', 'ma', 'weren', \"hadn't\", 'theirs', 'those', \"don't\", 'some', 'him', 'a', 'they', 'other', 'who', 'wouldn', 'll', \"you'll\", 'this', 'doesn', \"that'll\", 'such', \"needn't\", 'been', 'she', 'which', 'themselves', 'when', 'is', 'to', 'itself', 'had', 'was', 'were', 'once', 'our', \"hasn't\", 'but', 'while', 'why', 'not', 'too', 'there', 'more', 'shouldn', 'how', \"wouldn't\", 'them', 'doing', 'does', 'before', 'own', 'ours', \"mustn't\", 'then', \"didn't\", 'hasn', 'or', \"it's\", 'into', 'yours', 'in', 'me', 'd', 'about', \"shouldn't\", 'didn', 'himself', \"you've\", 'don', 'mustn', \"mightn't\", 'until', 'won', 'of', \"wasn't\", \"should've\", 'off', 'we', 'both', 'few', 'very', 't', \"doesn't\", 'ain', 'and', 'are', 'it', 'its', 're', 'further', 'y', \"isn't\", 'against', 'down', 'under', 'up', 'only', 'yourself', 'all', 'shan', 'through', 'will', 'what', 've', 'her', 'with', 'by', 'below', 'needn', 'same', 'at', 'just', 'so', 'after', 'above', 'his', \"won't\", 'each', 'o', 'hadn', 'from', 's', 'aren', 'for', \"she's\", 'be', 'do', 'again', 'between', 'as', 'if', 'he', 'm'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a88fb",
   "metadata": {},
   "source": [
    "# Preprocessing Tweets\n",
    "\n",
    "The inspiration for the methods below to clean the data came from course homework and from the article \"Twitter Sentiment Analysis- A NLP Use-Case for Beginners\" by Gunjan Goyal\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32963bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting borderlands murder ,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming borders kill all,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting borderlands kill all,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming borderlands murder all,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting borderlands 2 murder all,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Tweet Sentiment\n",
       "0       im getting borderlands murder ,  Positive\n",
       "1              coming borders kill all,  Positive\n",
       "2      im getting borderlands kill all,  Positive\n",
       "3     im coming borderlands murder all,  Positive\n",
       "4  im getting borderlands 2 murder all,  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_stopwords(tweet):\n",
    "    return \" \".join([word for word in str(tweet).split() if word not in stop_words])\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda tweet: cleaning_stopwords(tweet))\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04834cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting borderlands murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming borders kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting borderlands kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming borderlands murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting borderlands 2 murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Tweet Sentiment\n",
       "0       im getting borderlands murder   Positive\n",
       "1              coming borders kill all  Positive\n",
       "2      im getting borderlands kill all  Positive\n",
       "3     im coming borderlands murder all  Positive\n",
       "4  im getting borderlands 2 murder all  Positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_punc = string.punctuation\n",
    "\n",
    "def cleaning_punc(tweet):\n",
    "    translator = str.maketrans('', '', string_punc)\n",
    "    return tweet.translate(translator)\n",
    "\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda x: cleaning_punc(x))\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d53ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting borderlands murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming borders kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting borderlands kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming borderlands murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting borderlands 2 murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Tweet Sentiment\n",
       "0       im getting borderlands murder   Positive\n",
       "1              coming borders kill all  Positive\n",
       "2      im getting borderlands kill all  Positive\n",
       "3     im coming borderlands murder all  Positive\n",
       "4  im getting borderlands 2 murder all  Positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_URLs(tweet):\n",
    "    return re.sub('((www.[^s]+) | (https?://[^s]+))',' ', tweet)\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda x: cleaning_URLs(x))\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce485f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting borderlands murder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coming borders kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting borderlands kill all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming borderlands murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting borderlands  murder all</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Tweet Sentiment\n",
       "0      im getting borderlands murder   Positive\n",
       "1             coming borders kill all  Positive\n",
       "2     im getting borderlands kill all  Positive\n",
       "3    im coming borderlands murder all  Positive\n",
       "4  im getting borderlands  murder all  Positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(tweet):\n",
    "    return re.sub('[0-9]+', '', tweet)\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda x: cleaning_numbers(x))\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfc6ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>[realized, windows, partition, mac, like, year...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>[realized, mac, window, partition, years, behi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>[realized, windows, partition, mac, years, beh...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>[realized, windows, partition, mac, like, year...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>[like, windows, partition, mac, like, years, b...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet Sentiment\n",
       "74677  [realized, windows, partition, mac, like, year...  Positive\n",
       "74678  [realized, mac, window, partition, years, behi...  Positive\n",
       "74679  [realized, windows, partition, mac, years, beh...  Positive\n",
       "74680  [realized, windows, partition, mac, like, year...  Positive\n",
       "74681  [like, windows, partition, mac, like, years, b...  Positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(tokenizer.tokenize)\n",
    "training_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196c248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [im, get, borderland, murder]\n",
       "1              [come, border, kill, all]\n",
       "2       [im, get, borderland, kill, all]\n",
       "3    [im, come, borderland, murder, all]\n",
       "4     [im, get, borderland, murder, all]\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "def stemming_text(data):\n",
    "    text = [stemmer.stem(word) for word in data]\n",
    "    return text\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda x: stemming_text(x))\n",
    "training_data['Tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b8d9765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [im, get, borderland, murder]\n",
       "1              [come, border, kill, all]\n",
       "2       [im, get, borderland, kill, all]\n",
       "3    [im, come, borderland, murder, all]\n",
       "4     [im, get, borderland, murder, all]\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing_text(data):\n",
    "    text = [lemmatizer.lemmatize(word) for word in data]\n",
    "    return text\n",
    "\n",
    "training_data['Tweet'] = training_data['Tweet'].apply(lambda x: lemmatizing_text(x))\n",
    "training_data['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c1d00",
   "metadata": {},
   "source": [
    "# Splitting Dataset into different Sentiment Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04ea11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = training_data.loc[training_data['Sentiment'] == 'Positive']\n",
    "negative_tweets = training_data.loc[training_data['Sentiment'] == 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e1f1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[biggest, dissappoin, life, came, year, ago, f...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[biggest, disappoint, life, came, year, ago]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[biggest, disappoint, life, came, year, ago]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[biggest, dissappoin, life, come, year, ago, f...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[biggest, male, dissappoin, life, came, hang, ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74665</th>\n",
       "      <td>[nvidia, realli, delay, week]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74666</th>\n",
       "      <td>[nvidia, delay, week]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74667</th>\n",
       "      <td>[nvidia, realli, delay, sever, week]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74668</th>\n",
       "      <td>[nvidia, realli, delay, flight, week]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74669</th>\n",
       "      <td>[nvidia, realli, delay, next, week]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22358 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet Sentiment\n",
       "24     [biggest, dissappoin, life, came, year, ago, f...  Negative\n",
       "25          [biggest, disappoint, life, came, year, ago]  Negative\n",
       "26          [biggest, disappoint, life, came, year, ago]  Negative\n",
       "27     [biggest, dissappoin, life, come, year, ago, f...  Negative\n",
       "28     [biggest, male, dissappoin, life, came, hang, ...  Negative\n",
       "...                                                  ...       ...\n",
       "74665                      [nvidia, realli, delay, week]  Negative\n",
       "74666                              [nvidia, delay, week]  Negative\n",
       "74667               [nvidia, realli, delay, sever, week]  Negative\n",
       "74668              [nvidia, realli, delay, flight, week]  Negative\n",
       "74669                [nvidia, realli, delay, next, week]  Negative\n",
       "\n",
       "[22358 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35119a2",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "\n",
    "The inspiration for this next part of the project came from the youtube tutorial located at:\n",
    "\n",
    "https://www.youtube.com/watch?v=OsSkjrNjqNI\n",
    "\n",
    "Titled: Twitter Sentiment Analysis (Naive Bayes Classifier) by Artificial Intelligence at UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d918b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positive = positive_tweets[:10327].Tweet\n",
    "train_positive = positive_tweets[:10327].Tweet\n",
    "\n",
    "test_negative = negative_tweets[:11179].Tweet\n",
    "train_negative = negative_tweets[:11179].Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b51ed5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([train_positive, train_negative])\n",
    "X_test = pd.concat([test_positive, test_negative])\n",
    "\n",
    "y_train = np.append(np.ones(len(train_positive)), np.zeros(len(train_negative)))\n",
    "y_test = np.append(np.ones(len(test_positive)), np.zeros(len(test_negative)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e33cb0",
   "metadata": {},
   "source": [
    "# Frequency Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "285a6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    \n",
    "    tweet = cleaning_stopwords(tweet)\n",
    "    tweet = cleaning_punc(tweet)\n",
    "    tweet = cleaning_URLs(tweet)\n",
    "    tweet = cleaning_numbers(tweet)\n",
    "    tweet = tokenizer.tokenize(tweet)\n",
    "    tweet = stemming_text(tweet)\n",
    "    tweet = lemmatizing_text(tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2c1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency(tweets, y_value):\n",
    "    \n",
    "    frequency_dictionary = {}\n",
    "    \n",
    "    for tweet, y in zip(tweets, y_value):\n",
    "        for word in process_tweets(tweet):\n",
    "            \n",
    "            pair = (word, y)\n",
    "            \n",
    "            if pair in frequency_dictionary:\n",
    "                frequency_dictionary[pair] += 1\n",
    "                \n",
    "            else:\n",
    "                frequency_dictionary[pair] = frequency_dictionary.get(pair, 1)\n",
    "        \n",
    "    return frequency_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a62c3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = create_frequency(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9ba99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, X_train, y_train):\n",
    "    \n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "    \n",
    "    unique_words = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(unique_words)\n",
    "    \n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        \n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[(pair)]\n",
    "            \n",
    "        else:\n",
    "            N_neg += freqs[(pair)]\n",
    "            \n",
    "    D = y_train.shape[0]\n",
    "    \n",
    "    D_pos = sum(y_train)\n",
    "    \n",
    "    D_neg = D - sum(y_train)\n",
    "    \n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "    \n",
    "    for word in unique_words:\n",
    "        \n",
    "        frequency_positive = freqs.get((word, 1), 0)\n",
    "        frequency_negative = freqs.get((word, 0), 0)\n",
    "        \n",
    "        probability_word_positive = (frequency_positive + 1) / (N_pos + V)\n",
    "        probability_word_negative = (frequency_negative + 1) / (N_neg + V)\n",
    "        \n",
    "        loglikelihood[word] = np.log(probability_word_positive / probability_word_negative)\n",
    "        \n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9f00340",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b6c49",
   "metadata": {},
   "source": [
    "# Predicting Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2494a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "\n",
    "    word_list = process_tweets(tweet)\n",
    "\n",
    "    probability = 0\n",
    "\n",
    "    probability += logprior\n",
    "\n",
    "    for word in word_list:\n",
    "\n",
    "        if word in loglikelihood:\n",
    "\n",
    "            probability += loglikelihood[word]\n",
    "\n",
    "        return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8f3d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.43\n",
      "angry -> -1.37\n",
      "sad -> -0.75\n",
      "I am so excited -> 0.43\n",
      "good -> 1.19\n"
     ]
    }
   ],
   "source": [
    "for tweet in ['I am happy', 'angry', 'sad', 'I am so excited', 'good']:\n",
    "    \n",
    "    probability = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
    "    \n",
    "    print(f'{tweet} -> {probability:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e334e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
